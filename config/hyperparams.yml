common:
  gamma: 0.99

dqn:
  lr: 0.0001
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 0.995
  target_update_steps: 1000
  train_freq: 4
  hidden_layers: [128, 128]

dueling:
  lr: 0.0001
  epsilon_start: 1.0
  epsilon_end: 0.01
  epsilon_decay: 0.999
  target_update_steps: 1000
  train_freq: 4
  hidden_layers: [128, 128]  # recommended to add for consistency

ppo:
  lr: 0.00025
  entropy_coeff: 0.001
  clip_epsilon: 0.1
  ppo_epochs: 5

environment:
  use_lidar: false
  render_mode: null

training:
  max_episodes: 10000
  buffer_size: 50000
  batch_size: 2048
  train_start: 2048
  target_reward: 300         
  reward_window: 100
  patience: 20
